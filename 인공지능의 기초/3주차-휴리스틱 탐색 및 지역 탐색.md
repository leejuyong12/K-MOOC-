# 3주차



## 휴리스틱 탐색 및 지역 탐색



### 3-1. 휴리스틱 탐색

- BFS와 DFS는 Uninformed search strategies
  - 문제를 정의하는데 필요한 4가지 요소, 외에는 전혀 주어지지 않은 상태에서 탐색
- 휴리스틱 탐색은 Informed search strategies
  - Evaluation function을 보고 가장 바람직한 것부터 탐색
- Greedy best-first search
  - 평가함수를 그대로 휴리스틱 함수의 값으로 활용한다.
- A* search(A-star)
  - Evaluation function을 정할 때 추가적으로 한가지 정보를 더 활용
  - g(n)이라고 되어 있는데, g(n)이라는 건 n 노드까지 오는데 걸린 시간이었다.
  - 이미 비싼 비용을 치뤘다면 그 노드를 활용하지 않고 다른 노드를 펼친다.
  - 많은 경우에 더 optimal한 솔루션을 찾을 수 있다.

![캡처](md-images/%EC%BA%A1%EC%B2%98-1635563475305.PNG)

- 휴리스틱 함수를 정의하는데에는 trade-off 가 있다.
  - 처음에는 예측을 기반으로 정의하는데, 좋은 휴리스틱 함수를 정의하는 노력, 그리고 그 함수를 활용해서 goal을 찾는 노력 간 trade-off가 있다.

- 어떤 상황에서 A* 알고리즘을 사용했을 때 최적의 솔루션을 찾을 수 있는가?
  - 휴리스틱 함수가 admissible하다고 얘기하는 경우가 있다.
  - 이것은 어떤 경우냐고 하면, 우리가 사용하는 휴리스틱 함수 값이 실제 그 노드에서 goal까지의 true cost보다 항상 작거나 같은 경우를 우리가 admissible이라고 한다. (under estimate)
  - 직선거리는 항상 실제보다 더 작다.
- 왜 admissible하면 A*알고리즘이 optimal한 솔루션을 주는지 증명해보자.
  - 3가지 정의
    - G2 - suboptimal goal - 최적의 goal은 아니다
    - G - 최적의 path를 통해서 goal을 도달한 경우
    - n이라는 노드는 아직 펼쳐지지 않는 노드
    - 첫번째. f(G2) = g(G2)
      - G2는 goal이기 때문에 G2에서의 휴리스틱 함수의 값은 0이다.
      - 그렇기 때문에 G2에서 goal까지의 estimate distance 는 G2가 goal이기 때문에 당연히 0이 되어야 한다. 그래서 G2에서는 f값과 g값이 동일하게 된다.
    - 두번째. g(G2) > g(G)
      - G2는 suboptimal goal이고 G는 optimal goal이다.
      - 그런데 g라는 함수가 시작점에서 그 노드까지 가는 데 걸린 cost이기 때문에 당연히 suboptimal goal의 G값보다는 실제 optimal G값이 훨씬 크게 된다.
    - 세번째. f(G) = g(G)
      - g는 goal이기 때문에 휴리스틱 함수값은 0이된다.
    - 네번째. f(G2) > f(G) 
      - 위의 결론들을 통해 도출 된다. 

![캡처](md-images/%EC%BA%A1%EC%B2%98-1635564611019.PNG)

![캡처](md-images/%EC%BA%A1%EC%B2%98-1635564652198.PNG)

- 첫번째 수식은 이전거 그대로 가져왔고
- 두번째 수식은 h가 admissible하다고 가정을 했기 때문에 h(n)은 실제 n에서의 true cost보다는 항상 작거나 같게 된다.
- 세번째 수식은 두번째 수식으로부터 바로 올 수가 있는데, 두번째 수식에서 양쪽에 g(n)이라는 값을 동시에 더하게 된다.
  - 그래서 부등호의 경우에는 똑같은 수를 양쪽에 더하면, 그 부등호 방향은 바뀌지 않기 때문에 세번째 결론도 쉽게 얻을 수가 있다.
- 마지막 수식은 n이라는 노드는 시작노드에서 g라는 goal노드까지 가는 중간에 있는 노드 이기 때문에 f(n)은 항상 f(G)보다 작거나 같아야 한다.
  - 그렇기 때문에 cost는 노드를 가면 갈수록 항상 커지거나 같아야만 하기 때문에 이런 결론을 얻을 수 있다.

그러므로

- f(G2) > f(n)이라는 결론을 얻을 수 있다.
- f(G2) 즉 suboptimal한 노드는 n, optimal한 path 상에 있는 노드 대신에 펼쳐지는 경우가 절대 없다.

### 3-2. 지역 탐색

- Local search
  - 딥러닝
  - 실제로 많이 사용된다.
- 목적까지의 path가 중요하지는 않고, 그냥 목적을 달성하는 그 자체가 중요할때
  - ex) 체스 - 왕을 잡는 것이 목적
- 현재 어떤 state에 있다고 할 때, 내가 어떤 액션을 취해서 바로 갈 수 있는 인접한 state들 중에 지금 내 state보다 더 낫다고 판단되는 곳이 있으면 그것을 그냥 취하겠다.
- 메모리를 적게 필요로 한다.
- 대표적으로 N-Queens 문제
- Hill-Climbing Search
  - 안개때문에 멀리 못보고 바로 주변만 볼 수 있다.
  - 기억상실증에 걸렸다는 가정(다시 있던 자리로 되돌아올수도 있다)
  - Steepest ascent : 가장 급한 쪽으로 올라간다.
  - Greedy local search : 문제를 길게 탐색하지 않고 내가 바로 취할 수 있는 행동 중에 취하는 것
  - 치명적인 단점 : local maximization할 수도 있다.(근시안적인 해결)
  - initial point를 어디로 잡느냐에 따라 결과가 매우 달라진다.
- 위의 단점을 해결하기 위해 나온 것이 Simulated Annealing Search (Annealing : 담금질)
  - 금속의 강도를 높이기 위해 가열을 했다가 급격히 식혔다를 반복하는 과정에서 아이디어를 얻음
  - key idea는 Hill Climbing search 방법에서는 각 스텝마다 움직일 수 있는 액션들 중에서 무조건 제 objective를 최대화하는 그런 모션을 했다고 한다면,
  - Simulated Annealing Search 에서는 중간중간 현재 상태보다 좋지는 않지만 안좋은 move를 허락을 하는데, 그 안좋은 move를 허락하는 빈도를 처음에는 크게 줬다가, 가면 갈수록 그것을 줄여주는 방식
  - hill climbing search는 계속 올라가기만 하는데 여기는 내려갈수도 있다.( + random walk)
